{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baking-indiana",
   "metadata": {},
   "source": [
    "# Catchment characteristics\n",
    "\n",
    "We will see how to extract specific catchments from model outputs and their main rivers longitudinal profiles.\n",
    "\n",
    "## Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pooch\n",
    "from script import readOutput as rout\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "from pysheds.grid import Grid\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_size = 7\n",
    "matplotlib.rcParams['xtick.labelsize'] = label_size\n",
    "matplotlib.rcParams['ytick.labelsize'] = label_size\n",
    "matplotlib.rc('font', size=6)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-nitrogen",
   "metadata": {},
   "source": [
    "We first define a folder where exported files will be stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'export'\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-gospel",
   "metadata": {},
   "source": [
    "## Building a Netcdf file\n",
    "\n",
    "As for many of the approach described in these examples, we start by building from our `gospl` outputs a `netcdf` file.\n",
    "\n",
    "\n",
    "As we saw previously, `netcdf` exports are done by using the `readOutput.py` script presented in the previous notebook. Here we export all the time steps at once by looping through the number of outputs (5 in this case).\n",
    "\n",
    ":::{admonition} Arguments for `readOutput.py`\n",
    ":class: note, dropdown\n",
    "\n",
    "The `readOutput.py` script main function requires several arguments:\n",
    "\n",
    "+ `path`: the path to the input file\n",
    "+ `filename`: the name of the input file\n",
    "+ `step`: the step you wish to output (here set to 5 corresponding to the last output based on the input parameters: start time 0 year, end time 50 thousand years with an output every 10 thousand years)\n",
    "+ `nbstep`: the number of time steps to plot (useful if one want to output a `netdcf` file containing all time steps (done in the following section).\n",
    "+ `uplift_forcing`: set to False as we are not considering any tectonic forcing\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "Then the `buildLonLatMesh` function is used to interpolate (using a `kd-tree` approach) the `gospl` variables on a regular mesh. It also provides a way to limit the created `netcdf` file by defining a `bounding box`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift_forcing = False\n",
    "\n",
    "# Specifying the grid resolution in degrees\n",
    "reso = 0.1\n",
    "\n",
    "# Total number of outputs\n",
    "nbstep = 5\n",
    "\n",
    "# Bounding box\n",
    "bb = [-134,12,-46,80]\n",
    "\n",
    "def build_ncgrid(ncout, nbstep, bbox, reso, fname, uplift_forcing):\n",
    "\n",
    "    # Looping through the output time steps\n",
    "    for k in range(nbstep+1):\n",
    "        if k == 0:\n",
    "            # Calling the initialisation function for our class \n",
    "            ncgrid = rout.readOutput(path='./', filename=fname, \n",
    "                                     step=k, nbstep=nbstep+1, \n",
    "                                     uplift=uplift_forcing)\n",
    "        else:\n",
    "            # Update the variables after the first time steps\n",
    "            ncgrid.update(step=k, uplift=uplift_forcing)\n",
    "\n",
    "        # Build the regular grid defining the bounding box\n",
    "        ncgrid.buildLonLatMesh(res=reso, nghb=3, box=bbox)\n",
    "    \n",
    "    # Export as netcdf\n",
    "    ncgrid.exportNetCDF(ncfile = ncout)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-yugoslavia",
   "metadata": {},
   "source": [
    "Calling the function `build_ncgrid` to export the `netcdf` file on the desired bounding box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-starter",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "ncout = os.path.join(out_path, \"GoMresult.nc\")\n",
    "# We commented the next line and loaded the dataset from figshare (see below)\n",
    "build_ncgrid(ncout, nbstep, bb, reso, fname='input.yml', uplift_forcing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-wilderness",
   "metadata": {},
   "source": [
    "Here we will download the file directly from [figshare](https://figshare.com/s/19c544e94a08570c476d):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-cologne",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# ncout = pooch.retrieve(\n",
    "#     url=\"https://ndownloader.figshare.com/files/27579284\",\n",
    "#     known_hash=\"sha256:fdc4a4ac70bca66ed20c3a126fdbf8fd2b33a2b47170e45c53eaf96f20f42a32\",\n",
    "#     downloader=pooch.HTTPDownloader(progressbar=True),\n",
    "#     fname=\"GoMresult.nc\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-fiction",
   "metadata": {},
   "source": [
    "## Visualising with `xarray`\n",
    "\n",
    "Let first use the `netcdf` file created and open it with the `xarray` library in the jupyter environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(ncout, decode_times=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-graphic",
   "metadata": {},
   "source": [
    "By default the mesh is written in lon/lat (projection [epsg:4326](https://spatialreference.org/ref/epsg/wgs-84/) as `gospl` is a global model). \n",
    "\n",
    "Using the `rioxarray` library we have the ability to reproject the dataset in any other type of projection. Let's reproject the dataset in `utm` coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rio.write_crs(4326)\n",
    "print('Default projection:',ds.rio.crs)\n",
    "\n",
    "print('Estimated UTM projection:',ds.rio.estimate_utm_crs())\n",
    "ds_utm = ds.rio.reproject(ds.rio.estimate_utm_crs())\n",
    "\n",
    "ds_utm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-italy",
   "metadata": {},
   "source": [
    "We will now take a specific time step using the `isel` function (here we chose the last time step) and extract the elevation data variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the last time step of the elevation array\n",
    "elevArray = ds_utm.isel(time=[-1])[\"elevation\"][0,:,:]\n",
    "\n",
    "# Assigning a value of -9999.0 to all point below sea-level\n",
    "elevArray = elevArray.where(elevArray>0, other=-9999.0)\n",
    "\n",
    "# Export to geotiff\n",
    "tifout = os.path.join(out_path, \"GoMtime5.tif\")\n",
    "elevArray.rio.to_raster(tifout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-perfume",
   "metadata": {},
   "source": [
    "## Using `pysheds` library for watershed delineation\n",
    "\n",
    ":::{note}\n",
    "Information regarding the `pysheds` library can be found on the project github [page](https://github.com/mdbartos/pysheds).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotraster(grd, data, nd, label, v_min, v_max, cmap='Blues'):\n",
    "    '''\n",
    "    Simple plotting function to visualise the raster dataset\n",
    "    '''\n",
    "    data = np.ma.masked_array(data, mask = (data <= nd))\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    ax = plt.gca()\n",
    "    im = plt.imshow(data, extent=grd.extent, cmap=cmap, vmin=v_min, vmax=v_max)\n",
    "    \n",
    "    plt.colorbar(im, label=label, shrink=0.5)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-dollar",
   "metadata": {},
   "source": [
    "We first read the DEM data (*i.e.* the geotiff file created above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid.from_raster(tifout, data_name='dem')\n",
    "dem = grid.view('dem', nodata=-9999.0)\n",
    "dem[dem == -9999] = np.nan\n",
    "\n",
    "\n",
    "# Compute the depressions\n",
    "grid.fill_depressions('dem', out_name='filled',\n",
    "                      nodata_in = -9999, nodata_out = -9999)\n",
    "filled = grid.view('filled', nodata = -9999).astype(np.float32)\n",
    "\n",
    "# Resolve flat areas\n",
    "grid.resolve_flats(data='filled', out_name='demnoflat',\n",
    "                   nodata_in = -9999, nodata_out = -9999)\n",
    "demnoflat = grid.view('demnoflat', nodata = -9999).astype(np.float32)\n",
    "\n",
    "# Compute the flow direction\n",
    "dirmap = (3, 2, 1, 8, 7, 6, 5, 4)\n",
    "grid.flowdir('demnoflat', out_name='d8', dirmap=dirmap,\n",
    "             nodata_in = -9999, nodata_out = -9999, pits = -9999, flats = -9999)\n",
    "d8 = grid.view('d8', nodata = -9999).astype(np.float32)\n",
    "\n",
    "# Compute the flow accumulation\n",
    "grid.accumulation(data='d8', out_name='flowd8')\n",
    "flowd8 = grid.view('flowd8', nodata = -9999).astype(np.float32)\n",
    "flowd8[d8 == -9999] = -9999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-quarterly",
   "metadata": {},
   "source": [
    "Let's visualise the generated outputs with our plotting function `plotraster`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-diploma",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotraster(grid, dem, -9999, 'Elevation (m)', -100, 3000, 'gist_earth')\n",
    "plotraster(grid, demnoflat - dem, -9999, 'fill no flat (m)', -25, 25, 'RdBu_r')\n",
    "plotraster(grid, d8, -9999, 'flow direction', -1, 8, 'Accent_r')\n",
    "plotraster(grid, flowd8, -9999, 'flow accumulation', 0, np.max(flowd8)/1000, 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-newfoundland",
   "metadata": {},
   "source": [
    "## Extracting specific outlets\n",
    "\n",
    "To extract specific catchments, `pysheds` requires the position of the outlet.\n",
    "\n",
    "Here we show how to extract some specific outlets based on the flow accumulation values. \n",
    "\n",
    ":::{note}\n",
    "The approach here could be automatised to make it easier for the user...\n",
    ":::\n",
    "\n",
    "We start by finding the maximum flow accumulation in the entire raster and we will use the corresponding catchment for our analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the point ID corresponding to the maximum flow accumulation value\n",
    "outletID = np.where(flowd8.flatten() == flowd8.max())[0]\n",
    "\n",
    "# Get the corresponding point coordinate\n",
    "outletPt = dem.coords[outletID,:][0]\n",
    "\n",
    "# Define this first outlet by x1,y1\n",
    "x1, y1 = outletPt[1], outletPt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-discussion",
   "metadata": {},
   "source": [
    "We now extract a second outlet corrsponding to the biggest river entering the Gulf of Mexico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the point ID corresponding to the maximum flow accumulation value in the Gulf of Mexico\n",
    "outletID = np.where(flowd8.flatten() == flowd8[600:800,500:700].max())[0]\n",
    "\n",
    "# Get the corresponding point coordinate\n",
    "outletPt = dem.coords[outletID,:][0]\n",
    "\n",
    "# Define this first outlet by x2,y2\n",
    "x2, y2 = outletPt[1], outletPt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-hello",
   "metadata": {},
   "source": [
    "Let's see where these 2 outlets are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.ma.masked_array(flowd8, mask = (flowd8 <= -9999))\n",
    "    \n",
    "plt.figure(figsize=(6,6))\n",
    "ax = plt.gca()\n",
    "im = plt.imshow(data, extent=grid.extent, cmap='Blues', vmin=0, vmax=np.max(flowd8)/1000)\n",
    "\n",
    "plt.plot(x1,y1, 'o', color='r', markersize=10, \n",
    "         markeredgecolor='k', markeredgewidth=1)\n",
    "plt.plot(x2,y2, 'o', color='g', markersize=10, \n",
    "         markeredgecolor='k', markeredgewidth=1)\n",
    "\n",
    "plt.colorbar(im, label='flow accumulation', shrink=0.5)\n",
    "\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-matter",
   "metadata": {},
   "source": [
    "## Get corresponding catchments\n",
    "\n",
    "We now define a function `getCatchment` which extract river network (up to a specified flow accumulation `threshold`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCatchment(geotiff, x, y, threshold):\n",
    "    '''\n",
    "    Extract a specific river network based on outlet position and flow accumulation threshold.\n",
    "    '''\n",
    "    \n",
    "    grd = Grid.from_raster(geotiff, data_name='dem')\n",
    "\n",
    "    grd.fill_depressions('dem', out_name='filled',\n",
    "                          nodata_in = -9999, nodata_out = -9999)\n",
    "    grd.resolve_flats(data='filled', out_name='inflated_dem')\n",
    "\n",
    "    dirmap = (3, 2, 1, 8, 7, 6, 5, 4)\n",
    "    grd.flowdir('inflated_dem', out_name='dir', dirmap=dirmap,\n",
    "                  nodata_in = -9999, nodata_out = -9999, \n",
    "                  pits = -9999, flats = -9999)\n",
    "    \n",
    "    grd.accumulation(data='dir', out_name='acc2')\n",
    "\n",
    "    acc2 = grd.view('acc2', nodata = -9999).astype(np.float32)\n",
    "    acc2[acc2==0] = -9999\n",
    "    \n",
    "    grd.catchment(data='dir', x=x, y=y, out_name='catch',\n",
    "                    recursionlimit=15000, xytype='label')\n",
    "\n",
    "    \n",
    "    grd.clip_to('catch', pad=(1,1,1,1))\n",
    "\n",
    "    grd.accumulation(data='catch', out_name='acc')\n",
    "    \n",
    "    acc = grd.view('acc', nodata = -9999).astype(np.float32)\n",
    "    acc[acc==0] = -9999\n",
    "    \n",
    "    branches = grd.extract_river_network('catch', 'acc', dirmap=dirmap, threshold=threshold, \n",
    "                                       nodata_in=-9999, routing='d8',\n",
    "                                       apply_mask=True)\n",
    "    \n",
    "    data = np.ma.masked_array(acc, mask = (acc <= -9999))\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = plt.gca()\n",
    "    im = plt.imshow(data, extent=grd.extent, cmap='Blues', vmin=0, vmax=np.max(acc)/100)\n",
    "\n",
    "    plt.plot(x, y, 'o', color='r', markersize=10, markeredgecolor='k', markeredgewidth=1)\n",
    "    \n",
    "    plt.colorbar(im, label='flow accumulation', shrink=0.5)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    tree = spatial.cKDTree(dem.coords, leafsize=10)\n",
    "    \n",
    "    branch_df = []\n",
    "    nbbranches = len(branches['features'])\n",
    "    \n",
    "    for b in range(nbbranches):\n",
    "        branch = branches['features'][b]\n",
    "        branchXY = np.asarray(branch['geometry']['coordinates'])\n",
    "        branchXY = np.flip(branchXY,1)\n",
    "        dist, id = tree.query(branchXY, k=1)\n",
    "        elev = demnoflat.flatten()[id]\n",
    "        fa = acc2.flatten()[id]\n",
    "\n",
    "        data = np.vstack((branchXY[:,0], branchXY[:,1], \n",
    "                          elev, fa))\n",
    "        df = pd.DataFrame(data.T,\n",
    "                          columns = ['x','y','elev','fa'])\n",
    "        df = df[df.fa > -9999]\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        xx = df.x.to_numpy()\n",
    "        yy = df.y.to_numpy()\n",
    "        dx = xx[1:]-xx[:-1]\n",
    "        dy = yy[1:]-yy[:-1]\n",
    "        step_size = np.sqrt(dx**2+dy**2)\n",
    "        cumulative_distance = np.concatenate(([0], np.cumsum(step_size)))\n",
    "        df['dist'] = cumulative_distance\n",
    "\n",
    "        branch_df.append(df)\n",
    "        \n",
    "    \n",
    "    endbranch = None\n",
    "    maxfa = -10000\n",
    "    for b in range(nbbranches):\n",
    "        if branch_df[b].fa[0] > maxfa:\n",
    "            maxfa = branch_df[b].fa[0]\n",
    "            endbranch = b\n",
    "            \n",
    "    newdf = []\n",
    "    newdf.append(branch_df[endbranch])\n",
    "    for b in range(nbbranches):\n",
    "        if b != endbranch:\n",
    "            newdf.append(branch_df[b])\n",
    "        \n",
    "    return branches, newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-train",
   "metadata": {},
   "source": [
    "We call the function for the 2 outlets that were defined previously. The function returns 2 variables:\n",
    "\n",
    "1. a dictionnary containing the geometry and coordinates of the main rivers\n",
    "2. a `pandas` dataframe containing for each river the associated flow and elevation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#branches1, bdf1 = getCatchment(geotiff=tifout, x=x1, y=y1, threshold=2000)\n",
    "branches2, bdf2 = getCatchment(geotiff=tifout, x=x2, y=y2, threshold=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-lodging",
   "metadata": {},
   "source": [
    "### Plotting river networks \n",
    "\n",
    "The river networks can be obtained directly from the previous function first variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBranch(branchnb):\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for branch in branchnb['features']:\n",
    "        line = np.asarray(branch['geometry']['coordinates'])\n",
    "        plt.plot(line[:, 0], line[:, 1], lw=3)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotBranch(branches1)\n",
    "plotBranch(branches2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-advertiser",
   "metadata": {},
   "source": [
    "### Longitudinal profiles\n",
    "\n",
    "The second variable can be used to extract river longitudinal profile. To do so we define a new function `combineBranch` which connect each individual trunk together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineBranch(branch_df):\n",
    "    \n",
    "    check = True\n",
    "    \n",
    "    pp = 0\n",
    "    nbbranches = len(branch_df)\n",
    "    while(check):\n",
    "        for b in range(0,nbbranches):\n",
    "            row1 = branch_df[b].iloc[0]\n",
    "            x1, y1, dist1 = row1.x, row1.y, row1.dist\n",
    "\n",
    "            lastrow = np.array(branch_df[b].tail(1))[0]\n",
    "            xend, yend, distend = lastrow[0], lastrow[1], lastrow[-1]\n",
    "\n",
    "            for nextb in range(0,nbbranches):\n",
    "                if nextb != b:\n",
    "                    firstrow = branch_df[nextb].iloc[0]\n",
    "                    xstart, ystart, diststart = firstrow.x, firstrow.y, firstrow.dist\n",
    "                    changed = False\n",
    "                    if diststart == 0:\n",
    "                        if abs(xstart-xend) < 1. and abs(ystart-yend) < 1.0:\n",
    "                            if b == 0:\n",
    "                                branch_df[nextb].dist += distend\n",
    "                                changed = True\n",
    "                            else:\n",
    "                                if dist1 > 0.:\n",
    "                                    branch_df[nextb].dist += distend\n",
    "                                    changed = True\n",
    "                        if not changed:\n",
    "                            if abs(xstart-x1) < 1. and abs(ystart-y1) < 1.0:\n",
    "                                if b == 0:\n",
    "                                    branch_df[nextb].dist += 0.0001\n",
    "                                else:\n",
    "                                    branch_df[nextb].dist += dist1            \n",
    "        \n",
    "        check = False\n",
    "        for b in range(1,nbbranches):\n",
    "            if branch_df[b].iloc[0].dist == 0.:\n",
    "                check = True\n",
    "                \n",
    "        \n",
    "    return branch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-magic",
   "metadata": {},
   "source": [
    "Let's call the above function for each catchment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndf1 = combineBranch(branch_df=bdf1)\n",
    "ndf2 = combineBranch(branch_df=bdf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-office",
   "metadata": {},
   "source": [
    "We can now plot the longitudinal profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProfile(dataframe):\n",
    "    '''\n",
    "    Function for plotting the longitudinal profile.\n",
    "    '''\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for branch in range(len(dataframe)-1,-1,-1):\n",
    "        distance = np.asarray(dataframe[branch].dist)\n",
    "        elev = np.asarray(dataframe[branch].elev)\n",
    "\n",
    "        xnew = np.linspace(distance.min(), distance.max(), 10) \n",
    "        spl = make_interp_spline(distance, elev, k=3)  # type: BSpline\n",
    "        elev_smooth = spl(xnew)\n",
    "        elev_smooth[elev_smooth<0.] = 0.\n",
    "\n",
    "        plt.plot(xnew, elev_smooth, lw=3)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotProfile(ndf1)\n",
    "plotProfile(ndf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-consent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
